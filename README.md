# AI-Powered User Behavior Profiling & Threat Risk Scoring System

## ğŸ” Overview
This project implements an **AI-based User Behavior Analytics (UEBA)** system that learns
normal user behavior patterns, detects anomalies, and assigns **dynamic threat risk scores**
for cybersecurity monitoring.

The project demonstrates how **machine learning can be applied to cybersecurity use cases**
such as insider threat detection, compromised account identification, and cloud security
monitoring.

---

## ğŸ§© Problem Statement
Traditional security systems rely heavily on static rules and known attack signatures.
Such systems struggle to detect **unknown threats, insider attacks, and abnormal user
behavior patterns**.

There is a need for an **AI-driven behavioral analytics system** that can:
- Learn normal behavior automatically
- Detect deviations without labeled attack data
- Prioritize threats using risk scoring

---

## ğŸ¯ Objectives
- Perform user behavior profiling using machine learning
- Detect anomalous behavior patterns using unsupervised AI models
- Generate a dynamic threat risk score for each user
- Map AI outputs to real-world cybersecurity risks

---

## ğŸ§  Solution Approach
The system follows a modular AI pipeline:

1. **Feature Engineering**
   - Extracts and scales behavioral features such as session duration, login attempts,
     failed logins, and data accessed.

2. **Behavior Profiling**
   - Uses KMeans clustering to group users based on behavioral patterns.

3. **Anomaly Detection**
   - Applies Isolation Forest to identify deviations from normal behavior.

4. **Threat Risk Scoring**
   - Combines anomaly indicators and behavioral signals to generate a risk score.
   - Classifies users into Low, Medium, or High risk categories.

---

## ğŸ—ï¸ System Architecture
 User Activity Logs
â†“
Feature Engineering & Scaling
â†“
Behavior Profiling (Clustering)
â†“
Anomaly Detection (Isolation Forest)
â†“
Threat Risk Scoring
â†“
Security Risk Interpretation


---

## ğŸ› ï¸ Technologies Used
- **Python**
- **Scikit-learn**
- **Pandas & NumPy**
- **Matplotlib**
- **Google Colab / Jupyter Notebook**

---

## ğŸ“ Project Structure
AI-User-Behavior-Threat-Risk-Scoring/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ AI_User_Behavior_Threat_Risk_Scoring.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ user_activity_logs.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ anomaly_detection.py
â”‚   â””â”€â”€ risk_scoring.py
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ threat_scores.csv
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore




---

## ğŸ” Cybersecurity Relevance
This project maps AI outputs to real-world cybersecurity scenarios, including:
- Insider threat detection
- Compromised account identification
- Brute-force login behavior
- Excessive or abnormal data access
- Cloud and SOC security monitoring

The approach aligns with **UEBA (User and Entity Behavior Analytics)** techniques used in
modern SIEM and cloud security platforms.

---

## ğŸ“Š Results
- Users with abnormal behavior patterns receive higher threat risk scores
- High-risk users are prioritized for security review
- The system detects suspicious behavior without relying on predefined attack signatures

---

## ğŸš€ Future Enhancements
- Integration with real cloud logs (AWS CloudTrail / Azure Monitor)
- Real-time threat scoring pipeline
- SIEM integration
- Explainable AI dashboards
- Deep learningâ€“based behavior modeling

---

## ğŸ“Œ Conclusion
This project demonstrates how **AI-driven behavioral analytics** can enhance cybersecurity
by detecting anomalies and prioritizing risks dynamically. By combining machine learning
with security reasoning, the system highlights the practical value of AI in modern
cloud and enterprise security environments.

---

## ğŸ‘©â€ğŸ’» Author
Developed as part of an **AIML-focused internship project** with a cybersecurity application
to strengthen AI and cloud security skills.
